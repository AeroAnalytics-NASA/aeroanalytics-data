"""
TEMPO NO2 Data Extraction to CSV
Gets ALL available NO2 pixels for North America (no sampling)
"""

import earthaccess
import xarray as xr
import numpy as np
import pandas as pd
from datetime import datetime, timedelta


def get_all_tempo_no2(bbox, datetime_str):
    """
    Get ALL TEMPO NO2 pixels (no sampling) for a region.
    
    Parameters
    ----------
    bbox : tuple
        (min_lon, min_lat, max_lon, max_lat)
    datetime_str : str
        UTC datetime "YYYY-MM-DD HH:MM:SS"
    
    Returns
    -------
    pd.DataFrame with columns: latitude, longitude, NO2_molec_cm2
    """
    
    print("üîê Authenticating with NASA Earthdata...")
    try:
        earthaccess.login(persist=True)
    except:
        earthaccess.login(strategy="interactive", persist=True)
    
    min_lon, min_lat, max_lon, max_lat = bbox
    target_dt = datetime.fromisoformat(datetime_str.replace(" ", "T"))
    
    # Expand search window to ensure we get data
    start_time = (target_dt - timedelta(hours=3)).strftime("%Y-%m-%d %H:%M:%S")
    end_time = (target_dt + timedelta(hours=3)).strftime("%Y-%m-%d %H:%M:%S")
    
    print(f"üîç Searching for TEMPO NO2 data...")
    print(f"   Area: {bbox}")
    print(f"   Time: {datetime_str} UTC (¬±3 hours)")
    
    # Search for NO2 data
    results = earthaccess.search_data(
        short_name="TEMPO_NO2_L3",
        version="V03",
        bounding_box=(min_lon, min_lat, max_lon, max_lat),
        temporal=(start_time, end_time)
    )
    
    if not results:
        print("‚ùå No TEMPO data found in this time window")
        return pd.DataFrame()
    
    print(f"‚úÖ Found {len(results)} granule(s)")
    
    all_rows = []
    
    for idx, granule in enumerate(results):
        print(f"\nüìÇ Processing granule {idx + 1}/{len(results)}...")
        
        try:
            # Open file directly from cloud
            files = earthaccess.open([granule])
            ds = xr.open_dataset(files[0], group=None, engine='h5netcdf')
            
            # Open product group
            try:
                ds_product = xr.open_dataset(files[0], group='product', engine='h5netcdf')
            except:
                ds_product = ds
            
            # Get coordinates
            if 'latitude' in ds.coords:
                lat_vals = ds.coords['latitude'].values
                lon_vals = ds.coords['longitude'].values
            elif 'latitude' in ds.variables:
                lat_vals = ds.variables['latitude'].values
                lon_vals = ds.variables['longitude'].values
            else:
                print("   ‚ö†Ô∏è No coordinates found")
                continue
            
            # Get NO2 data
            var_name = "vertical_column_troposphere"
            if var_name not in ds_product.variables:
                print(f"   ‚ö†Ô∏è Variable {var_name} not found")
                continue
            
            # Extract data (first time step)
            data = ds_product[var_name].isel(time=0).values
            
            # Get quality flag
            if "main_data_quality_flag" in ds_product.variables:
                qf = ds_product["main_data_quality_flag"].isel(time=0).values
            else:
                qf = np.zeros_like(data, dtype=int)
            
            print(f"   Data shape: {data.shape}")
            print(f"   Lat range: {lat_vals.min():.2f} to {lat_vals.max():.2f}")
            print(f"   Lon range: {lon_vals.min():.2f} to {lon_vals.max():.2f}")
            
            # Subset to bounding box
            lat_mask = (lat_vals >= min_lat) & (lat_vals <= max_lat)
            lon_mask = (lon_vals >= min_lon) & (lon_vals <= max_lon)
            
            if not np.any(lat_mask) or not np.any(lon_mask):
                print("   ‚ö†Ô∏è No data in bounding box")
                continue
            
            # Apply spatial mask
            subset_data = data[lat_mask, :][:, lon_mask]
            subset_qf = qf[lat_mask, :][:, lon_mask]
            subset_lat = lat_vals[lat_mask]
            subset_lon = lon_vals[lon_mask]
            
            # Create 2D coordinate grids
            lon_grid, lat_grid = np.meshgrid(subset_lon, subset_lat)
            
            # Filter for valid data
            # Quality flag = 0 (good)
            # Data is finite and positive
            valid_mask = (subset_qf == 0) & np.isfinite(subset_data) & (subset_data > 0)
            
            valid_count = np.sum(valid_mask)
            print(f"   Valid pixels: {valid_count:,} / {valid_mask.size:,}")
            
            if valid_count == 0:
                print("   ‚ö†Ô∏è No valid pixels")
                continue
            
            # Extract valid pixels
            valid_lats = lat_grid[valid_mask]
            valid_lons = lon_grid[valid_mask]
            valid_no2 = subset_data[valid_mask]
            
            # Create DataFrame for this granule
            df_granule = pd.DataFrame({
                'latitude': valid_lats,
                'longitude': valid_lons,
                'NO2_molec_cm2': valid_no2
            })
            
            all_rows.append(df_granule)
            print(f"   ‚úÖ Extracted {len(df_granule):,} pixels")
            
        except Exception as e:
            print(f"   ‚ùå Error: {str(e)}")
            continue
    
    if not all_rows:
        print("\n‚ùå No valid data extracted")
        return pd.DataFrame()
    
    # Combine all granules
    df_final = pd.concat(all_rows, ignore_index=True)
    
    # Remove duplicates (if any overlap between granules)
    initial_count = len(df_final)
    df_final = df_final.drop_duplicates(subset=['latitude', 'longitude'])
    final_count = len(df_final)
    
    if initial_count > final_count:
        print(f"\nüßπ Removed {initial_count - final_count:,} duplicate pixels")
    
    print(f"\n‚úÖ Total valid NO2 pixels: {final_count:,}")
    
    return df_final


# =============================================================================
# MAIN
# =============================================================================

if __name__ == "__main__":
    # Configuration
    NORTH_AMERICA_BBOX = (-160, 10, -40, 60)
    
    # Use a date with good TEMPO coverage
    # TEMPO launched August 2023, use dates from Sept 2023 onwards
    # Afternoon UTC (18:00-20:00) typically has best coverage
    DATETIME = "2025-07-01 19:00:00"  # UTC - 3PM EST, good coverage time
    
    # Output file
    OUTPUT_CSV = f"tempo_no2_north_america{DATETIME}.csv"
    
    print("="*70)
    print("TEMPO NO2 Data Extraction - Full Resolution")
    print("="*70)
    print(f"Coverage: North America {NORTH_AMERICA_BBOX}")
    print(f"DateTime: {DATETIME} UTC")
    print(f"Output: {OUTPUT_CSV}")
    print(f"Mode: Extract ALL valid pixels (no sampling)")
    print("="*70 + "\n")
    
    # Get ALL NO2 data
    df = get_all_tempo_no2(
        bbox=NORTH_AMERICA_BBOX,
        datetime_str=DATETIME
    )
    
    # Save to CSV
    if len(df) > 0:
        # Sort by latitude, longitude for cleaner output
        df = df.sort_values(['latitude', 'longitude']).reset_index(drop=True)
        
        df.to_csv(OUTPUT_CSV, index=False)
        print(f"\n‚úÖ Saved {len(df):,} rows to {OUTPUT_CSV}")
        
        print(f"\nFirst 10 rows:")
        print(df.head(10))
        
        print(f"\nData Summary:")
        print("="*70)
        print(f"Total pixels: {len(df):,}")
        print(f"\nLatitude range: {df['latitude'].min():.2f}¬∞ to {df['latitude'].max():.2f}¬∞")
        print(f"Longitude range: {df['longitude'].min():.2f}¬∞ to {df['longitude'].max():.2f}¬∞")
        print(f"\nNO2 Statistics (molec/cm¬≤):")
        print(f"  Min:  {df['NO2_molec_cm2'].min():.2e}")
        print(f"  Max:  {df['NO2_molec_cm2'].max():.2e}")
        print(f"  Mean: {df['NO2_molec_cm2'].mean():.2e}")
        print(f"  Median: {df['NO2_molec_cm2'].median():.2e}")
        
        # Show spatial coverage
        print(f"\nSpatial Coverage:")
        lat_bins = pd.cut(df['latitude'], bins=10)
        print(f"  Pixels per latitude band:")
        print(lat_bins.value_counts().sort_index())
        
    else:
        print("\n‚ùå No data to save")
        print("\nTips:")
        print("  ‚Ä¢ Try a different date/time")
        print("  ‚Ä¢ TEMPO data available from August 2023 onwards")
        print("  ‚Ä¢ Best coverage: 18:00-20:00 UTC (afternoon North America)")
        print("  ‚Ä¢ Check https://www.earthdata.nasa.gov/learn/articles/tempo for data availability")